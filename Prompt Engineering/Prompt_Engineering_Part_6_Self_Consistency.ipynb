{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NdNa7F04QvYl"
      },
      "outputs": [],
      "source": [
        "# os: Operating system interactions (file/directory manipulation).\n",
        "import os\n",
        "\n",
        "# operator.itemgetter: Extracts items from sequences.\n",
        "from operator import itemgetter\n",
        "\n",
        "# langchain_openai.ChatOpenAI: Integration with OpenAI's chat models for text generation.\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# langchain.prompts.PromptTemplate: Predefined templates for generating prompts.\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# langchain.schema.StrOutputParser: Parses string outputs into structured data.\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "# langchain.schema.runnable.RunnablePassthrough: Wraps runnable objects for easier execution.\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "\n",
        "# IPython.display: Displays output in Jupyter notebooks, including Markdown.\n",
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WPc7IRdTg0D",
        "outputId": "4c356d9a-31bc-4a59-825a-e303fd672e6e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.51.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY']  = userdata.get('OPEN_API_KEY')"
      ],
      "metadata": {
        "id": "WnjjctflTBBo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "#openai.api_key = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "P9qYzqnVTizH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompting"
      ],
      "metadata": {
        "id": "wBRwHPwwSkCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a question about apple quantities and usage.\n",
        "question = \"\"\"The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\"\"\"\n",
        "\n",
        "# Provide context for answering questions, emphasizing detailed math and reasoning.\n",
        "context = \"\"\"Answer questions showing the full math and reasoning. Follow the pattern in the example.\"\"\"\n",
        "\n",
        "# Example problem-solving scenario involving arithmetic calculations.\n",
        "one_shot_example = \"\"\"Example\n",
        "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he\n",
        "have now?\n",
        "\n",
        "A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
        "\n",
        "Q: \"\"\""
      ],
      "metadata": {
        "id": "qETIoQdxSj_p"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a structured response using PromptTemplate, ChatOpenAI, and StrOutputParser.\n",
        "answer_1 = (\n",
        "\n",
        "    # Start with a base response template followed by \"A: \".\n",
        "    PromptTemplate.from_template(context + one_shot_example + \" {input}\")\n",
        "\n",
        "    # Use ChatOpenAI with temperature set to 0 for deterministic output.\n",
        "    | ChatOpenAI(temperature=0)\n",
        "\n",
        "    # Parse the generated text into structured data.\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "et3iUfgrSj8t"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a structured response using PromptTemplate, ChatOpenAI, and StrOutputParser.\n",
        "answer_2 = (\n",
        "\n",
        "    # Start with a base response template followed by \"A: \".\n",
        "    PromptTemplate.from_template(context + one_shot_example + \" {input}\")\n",
        "\n",
        "    # Use ChatOpenAI with temperature set to 0 for deterministic output.\n",
        "    | ChatOpenAI(temperature=0.1)\n",
        "\n",
        "    # Parse the generated text into structured data.\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "wazk9W_JSj55"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a structured response using PromptTemplate, ChatOpenAI, and StrOutputParser.\n",
        "answer_3 = (\n",
        "\n",
        "    # Start with a base response template followed by \"A: \".\n",
        "    PromptTemplate.from_template(context + one_shot_example + \" {input}\")\n",
        "\n",
        "    # Use ChatOpenAI with temperature set to 0 for deterministic output.\n",
        "    | ChatOpenAI(temperature=0.7)\n",
        "\n",
        "    # Parse the generated text into structured data.\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "vAxhxT3FSj3J"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final responder setup for formatting and displaying results in markdown.\n",
        "final_responder = (\n",
        "\n",
        "    # Template for outputting results in markdown format.\n",
        "    PromptTemplate.from_template(\n",
        "        \"\"\"Output all the final results in this markdown format: Result 1: {results_1} \\n Result 2:{results_2} \\n Result 3:\n",
        "        {results_3}\"\"\"\n",
        "    )\n",
        "\n",
        "    # Process the template through ChatOpenAI for text generation.\n",
        "    | ChatOpenAI()\n",
        "\n",
        "    # Parse the generated text into structured data.\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "l9YXHKqfSjz-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain together components for a comprehensive response process.\n",
        "chain = (\n",
        "\n",
        "    # Map each answer to specific variables.\n",
        "     {\n",
        "        \"results_1\": answer_1,\n",
        "        \"results_2\": answer_2,\n",
        "        \"results_3\": answer_3,\n",
        "    }\n",
        "\n",
        "    # Finalize the response with formatting and display.\n",
        "    | final_responder\n",
        ")"
      ],
      "metadata": {
        "id": "1fhaVfr7SjxJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the response chain with a given input question.\n",
        "answers = chain.invoke({\"input\": question})\n",
        "\n",
        "# Display the generated answers in Markdown format.\n",
        "display(Markdown(answers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "6oB3me59Sjuh",
        "outputId": "48ec585f-b604-4663-8e59-1e753ccfd8f8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Result 1: \nA: The cafeteria started with 23 apples. They used 20 apples for lunch, so they have 23 - 20 = 3 apples left. Then they bought 6 more apples, so they now have 3 + 6 = 9 apples. The answer is 9.\n\nResult 2:\nA: The cafeteria started with 23 apples. They used 20 for lunch, so they have 23 - 20 = 3 apples left. Then they bought 6 more apples, so they now have 3 + 6 = 9 apples. The answer is 9.\n\nResult 3:\nA: The cafeteria started with 23 apples. They used 20 to make lunch, so they have 23 - 20 = 3 apples left. Then, they bought 6 more apples. 3 + 6 = 9. The cafeteria now has 9 apples."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzUWFxZJSjr1",
        "outputId": "9cec04f8-ed32-4c8c-d7b7-184af9e3fac5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='Answer questions showing the full math and reasoning. Follow the pattern in the example.Example \\nQ: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he \\nhave now? \\n\\nA: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\\n\\nQ:  {input}')\n",
              "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7a91537f7d90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7a91539557e0>, root_client=<openai.OpenAI object at 0x7a91537f4e50>, root_async_client=<openai.AsyncOpenAI object at 0x7a91537f5b40>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
              "| StrOutputParser()"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}