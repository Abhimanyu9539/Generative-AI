{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7UTNgfW50cE",
        "outputId": "abc65f30-b87b-49f5-fd6d-976800f72c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/973.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.7/973.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.1/397.1 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.2.0 --quiet\n",
        "!pip install langchain-openai==0.1.7 --quiet\n",
        "!pip install langchain-community==0.2.0 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPEN_API_KEY')\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "os.environ['TAVILY_API_KEY'] = userdata.get('TAVILY_API_KEY')\n",
        "WEATHER_API_KEY = userdata.get('WEATHER_API_KEY')"
      ],
      "metadata": {
        "id": "SfzF3ZcI6Aa4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)"
      ],
      "metadata": {
        "id": "ykcQFmCS6AYg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Tools\n",
        "\n",
        "Here we create two custom tools which are wrappers on top of the [Tavily API](https://tavily.com/#api) and [WeatherAPI](https://www.weatherapi.com/)\n",
        "\n",
        "- Simple Web Search tool\n",
        "- Weather tool"
      ],
      "metadata": {
        "id": "WYcsQcMh6AWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.tools import tool\n",
        "import requests\n",
        "import json\n",
        "\n",
        "tv_search = TavilySearchResults(max_results=3, search_depth='advanced',\n",
        "                                max_tokens=10000)\n",
        "\n",
        "@tool\n",
        "def search_web(query: str) -> list:\n",
        "    \"\"\"Search the web for a query.\"\"\"\n",
        "    tavily_tool = TavilySearchResults(max_results=2)\n",
        "    results = tavily_tool.invoke(query)\n",
        "    return results\n",
        "\n",
        "@tool\n",
        "def get_weather(query: str) -> list:\n",
        "    \"\"\"Search weatherapi to get the current weather.\"\"\"\n",
        "    base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
        "    complete_url = f\"{base_url}?key={WEATHER_API_KEY}&q={query}\"\n",
        "\n",
        "    response = requests.get(complete_url)\n",
        "    data = response.json()\n",
        "    if data.get(\"location\"):\n",
        "        return data\n",
        "    else:\n",
        "        return \"Weather Data Not Found\""
      ],
      "metadata": {
        "id": "jQbeVtXk6AT2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Tool Calling with LLM"
      ],
      "metadata": {
        "id": "bm82lpvN6ARd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "tools = [search_web, get_weather]\n",
        "\n",
        "chatgpt_with_tools = chatgpt.bind_tools(tools)"
      ],
      "metadata": {
        "id": "RWR-Lm256APL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"who won the champions league in 2024\"\n",
        "response = chatgpt_with_tools.invoke(prompt)\n",
        "response.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvv_3LDv7anq",
        "outputId": "d59d9d95-2bbb-41aa-a534-cca0324a4911"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'search_web',\n",
              "  'args': {'query': 'Champions League 2024 winner'},\n",
              "  'id': 'call_5WVRZTFE5pZnaDpxX8UNhmqF',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"how is the weather in Bangalore today\"\n",
        "response = chatgpt_with_tools.invoke(prompt)\n",
        "response.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGodG-387cC1",
        "outputId": "664c523d-51e1-4efa-ce48-7e6a71670eb9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'get_weather',\n",
              "  'args': {'query': 'Bangalore'},\n",
              "  'id': 'call_c3esXhqfiWs0Vvy8tGVqmsBT',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and Test AI Agent\n",
        "\n",
        "Now that we have defined the tools and the LLM, we can create the agent. We will be using a tool calling agent to bind the tools to the agent with a prompt. We will also add in the capability to store historical conversations as memory"
      ],
      "metadata": {
        "id": "Wsh3hWs77ihV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "SYS_PROMPT = \"\"\"Act as a helpful assistant.\n",
        "                Use the tools at your disposal to perform tasks as needed.\n",
        "                  - get_weather: whenever user asks get the weather of a place.\n",
        "                  - search_web: whenever user asks for information on current events or if you don't know the answer.\n",
        "             \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", SYS_PROMPT),\n",
        "        MessagesPlaceholder(variable_name=\"history\", optional=True),\n",
        "        (\"human\", \"{query}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_template.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6EWvuhs7i9e",
        "outputId": "92680415-cfc2-4a70-95a9-ca45afcc477c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"Act as a helpful assistant.\\n                Use the tools at your disposal to perform tasks as needed.\\n                  - get_weather: whenever user asks get the weather of a place.\\n                  - search_web: whenever user asks for information on current events or if you don't know the answer.\\n             \")),\n",
              " MessagesPlaceholder(variable_name='history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}')),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can initalize the agent with the LLM, the prompt, and the tools.\n",
        "\n",
        "The agent is responsible for taking in input and deciding what actions to take.\n",
        "\n",
        "REMEMBER the Agent does not execute those actions - that is done by the AgentExecutor\n",
        "\n",
        "Note that we are passing in the model `chatgpt`, not `chatgpt_with_tools`.\n",
        "\n",
        "That is because `create_tool_calling_agent` will call `.bind_tools` for us under the hood.\n",
        "\n",
        "This should ideally be used with an LLM which supports tool \\ function calling"
      ],
      "metadata": {
        "id": "RLXHyFTc8tC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "\n",
        "agent = create_tool_calling_agent(chatgpt, tools, prompt_template)\n",
        "agent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plk5Aw9V8z-g",
        "outputId": "7a389838-f92b-4485-d5c9-309e52b7ec19"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunnableAssign(mapper={\n",
              "  agent_scratchpad: RunnableLambda(lambda x: format_to_tool_messages(x['intermediate_steps']))\n",
              "})\n",
              "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'query'], optional_variables=['history'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"Act as a helpful assistant.\\n                Use the tools at your disposal to perform tasks as needed.\\n                  - get_weather: whenever user asks get the weather of a place.\\n                  - search_web: whenever user asks for information on current events or if you don't know the answer.\\n             \")), MessagesPlaceholder(variable_name='history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
              "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x781ae1d9cfd0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x781ae172c050>, model_name='gpt-4o', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'search_web', 'description': 'Search the web for a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'get_weather', 'description': 'Search weatherapi to get the current weather.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}}, 'required': ['query']}}}]})\n",
              "| ToolsAgentOutputParser()"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we combine the `agent` (the brains) with the `tools` inside the `AgentExecutor` (which will repeatedly call the agent and execute tools)."
      ],
      "metadata": {
        "id": "XpR1v3wT9ClB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
        "agent_executor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hDHAAlU8zzz",
        "outputId": "f1055b9a-464f-4099-d85e-3aacc18f2fe4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentExecutor(agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
              "  agent_scratchpad: RunnableLambda(lambda x: format_to_tool_messages(x['intermediate_steps']))\n",
              "})\n",
              "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'query'], optional_variables=['history'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"Act as a helpful assistant.\\n                Use the tools at your disposal to perform tasks as needed.\\n                  - get_weather: whenever user asks get the weather of a place.\\n                  - search_web: whenever user asks for information on current events or if you don't know the answer.\\n             \")), MessagesPlaceholder(variable_name='history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
              "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x781ae1d9cfd0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x781ae172c050>, model_name='gpt-4o', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'search_web', 'description': 'Search the web for a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'get_weather', 'description': 'Search weatherapi to get the current weather.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}}, 'required': ['query']}}}]})\n",
              "| ToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[StructuredTool(name='search_web', description='Search the web for a query.', args_schema=<class 'pydantic.v1.main.search_webSchema'>, func=<function search_web at 0x781ae1bbf560>), StructuredTool(name='get_weather', description='Search weatherapi to get the current weather.', args_schema=<class 'pydantic.v1.main.get_weatherSchema'>, func=<function get_weather at 0x781ae1bbf6a0>)])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Tell me who won the champions league in 2024,\n",
        "            show some detailed information about the match also\n",
        "        \"\"\"\n",
        "response = chatgpt.invoke(query)\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "pRbTwN7u8ztd",
        "outputId": "96e4f9b9-5ea0-4538-8e7d-25a4230c2030"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, but I don't have access to real-time data or events beyond October 2023. Therefore, I cannot provide information about the winner of the UEFA Champions League in 2024 or any details about the match. You may want to check the latest sports news or the official UEFA website for the most up-to-date information.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Tell me who won the champions league in 2024,\n",
        "            show some detailed information about the match also\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})"
      ],
      "metadata": {
        "id": "j9N247UT9InZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sUHzCnJ9MMs",
        "outputId": "b1fc16a7-d336-4a30-dd30-0aa40c6ecaf6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Tell me who won the champions league in 2024,\\n            show some detailed information about the match also\\n        ',\n",
              " 'output': \"The 2024 UEFA Champions League final was held at Wembley Stadium in London, England, on June 1, 2024. Real Madrid emerged victorious, defeating Borussia Dortmund with a score of 2-0. This victory allowed Real Madrid to compete against the winners of the 2023–24 UEFA Europa League, Atalanta, in the 2024 UEFA Super Cup.\\n\\n### Match Details:\\n- **Final Score**: Real Madrid 2-0 Borussia Dortmund\\n- **Location**: Wembley Stadium, London, England\\n- **Date**: June 1, 2024\\n- **Player of the Match**: Dani Carvajal (Real Madrid)\\n- **Champions League Young Player of the Season**: Jude Bellingham (Real Madrid)\\n\\nReal Madrid's win in this match added another prestigious title to their illustrious history in European football.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "vHJnqoBf9QLL",
        "outputId": "f23eaaf6-31d9-4a6a-d7f9-b5f330f2e56b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The 2024 UEFA Champions League final was held at Wembley Stadium in London, England, on June 1, 2024. Real Madrid emerged victorious, defeating Borussia Dortmund with a score of 2-0. This victory allowed Real Madrid to compete against the winners of the 2023–24 UEFA Europa League, Atalanta, in the 2024 UEFA Super Cup.\n\n### Match Details:\n- **Final Score**: Real Madrid 2-0 Borussia Dortmund\n- **Location**: Wembley Stadium, London, England\n- **Date**: June 1, 2024\n- **Player of the Match**: Dani Carvajal (Real Madrid)\n- **Champions League Young Player of the Season**: Jude Bellingham (Real Madrid)\n\nReal Madrid's win in this match added another prestigious title to their illustrious history in European football."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"how is the weather in Bangalore today?\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "l2Fi0lzj9S3y",
        "outputId": "8d968646-3ae2-47ae-ca48-36326794076f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The weather in Bangalore today is clear with a temperature of 21.1°C (70.0°F). The wind is blowing from the east-southeast at 14.8 kph (9.2 mph), and the humidity is at 60%. There is no precipitation, and the visibility is 6.0 km (3.0 miles)."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"how is the weather in Dubai today?\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "FR9rZlxp9W5-",
        "outputId": "5eb08592-3697-4060-eb2e-fb4e13a9855c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The weather in Dubai today is clear with a temperature of 24.3°C (75.7°F). The wind is blowing from the northeast at 20.9 kph (13.0 mph), and the humidity is at 50%. There is no precipitation, and the visibility is 10 km (6 miles). The current conditions feel like 25.7°C (78.3°F)."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"which city is hotter?\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "o1mg5Quh-kyT",
        "outputId": "f9e1f1d5-3358-410c-d989-fc7f2ca6f2f0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Could you please specify the cities you would like to compare in terms of temperature?"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The agent is doing pretty well but unfortunately it doesn't remember conversations. Let's now use some memory to store this."
      ],
      "metadata": {
        "id": "mRf8K56N-oe5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and Test Multi-User Conversational AI Agent\n",
        "\n",
        "We will now use `SQLChatMessageHistory` which we learnt in the previous module to store separate conversation histories per user or session.\n",
        "\n",
        "This will help us build a conversational Agentic Chatbot which will be accessed by many users at the same time"
      ],
      "metadata": {
        "id": "d4G8XLY0-qvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# removes the memory database file - usually not needed\n",
        "# you can run this only when you want to remove ALL conversation histories\n",
        "# ok if you get rm: cannot remove 'memory.db': No such file or directory  because initially no memory exists\n",
        "!rm memory.db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emij2tFq-lEE",
        "outputId": "be6fd6d7-4a52-4a3b-f8c5-d05fe98c5e0d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'memory.db': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "# used to retrieve conversation history from database\n",
        "# based on a specific user or session ID\n",
        "def get_session_history_db(session_id):\n",
        "    return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")\n",
        "\n",
        "# create a conversation chain + agent which can load memory based on specific user or session id\n",
        "agentic_chatbot = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    get_session_history_db,\n",
        "    input_messages_key=\"query\",\n",
        "    history_messages_key=\"history\",\n",
        ")\n",
        "\n",
        "# function to call the agent show results per user session\n",
        "from IPython.display import display, Markdown\n",
        "def chat_with_agent(prompt: str, session_id: str):\n",
        "    response = agentic_chatbot.invoke({\"query\": prompt},\n",
        "                                      {'configurable': { 'session_id': session_id}})\n",
        "    display(Markdown(response['output']))"
      ],
      "metadata": {
        "id": "DXSxZPMd-tBj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 'john001'\n",
        "prompt = \"Hi can you tell me who won champions league in 2024\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "eXavE5gp-ulL",
        "outputId": "715ff83e-b174-449c-c65e-9bbfc6a7737e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The winner of the 2024 UEFA Champions League was Real Madrid. They defeated Dortmund 2-0 in the final held at Wembley Stadium in London."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Tell me more about this event in detail please\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "I62Y0i97-1cW",
        "outputId": "b1297bd0-ec52-4588-ba08-4797820857c0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Real Madrid won the 2024 UEFA Champions League final by defeating Borussia Dortmund 2-0. The match took place at Wembley Stadium in London. This victory marked Real Madrid's 15th Champions League title, further extending their record as the club with the most titles in the competition's history.\n\nFor more detailed highlights and information, you can visit the [UEFA website](https://www.uefa.com/uefachampionsleague/match/2039970--b-dortmund-vs-real-madrid/) or check out the [ESPN match report](https://www.espn.com/soccer/match/_/gameId/702410/real-madrid-borussia-dortmund)."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"how is the weather in Bangalore today? Show detailed statistics\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "FJ6Dpe_3-3bB",
        "outputId": "997a489b-1ab2-4fb2-f0b8-911f44fb6c46"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The current weather in Bangalore, Karnataka, India is as follows:\n\n- **Temperature**: 21.1°C (70.0°F)\n- **Condition**: Clear\n- **Wind**: 9.2 mph (14.8 kph) from the East-Southeast (ESE) at 106°\n- **Pressure**: 1017.0 mb (30.03 in)\n- **Precipitation**: 0.0 mm (0.0 in)\n- **Humidity**: 60%\n- **Cloud Cover**: 0%\n- **Feels Like**: 21.1°C (70.0°F)\n- **Wind Chill**: 21.4°C (70.6°F)\n- **Heat Index**: 24.3°C (75.7°F)\n- **Dew Point**: 10.3°C (50.5°F)\n- **Visibility**: 6.0 km (3.0 miles)\n- **UV Index**: 0.0\n- **Wind Gusts**: 16.1 mph (25.9 kph)\n\nThe weather is clear with no cloud cover, and the temperature feels quite comfortable."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"what about Dubai?\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "3xbshjGr-60K",
        "outputId": "38709739-b842-4282-8998-c1046cf2c9cb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The current weather in Dubai, United Arab Emirates is as follows:\n\n- **Temperature**: 24.3°C (75.7°F)\n- **Condition**: Clear\n- **Wind**: 13.0 mph (20.9 kph) from the Northeast (NE) at 52°\n- **Pressure**: 1013.0 mb (29.91 in)\n- **Precipitation**: 0.0 mm (0.0 in)\n- **Humidity**: 50%\n- **Cloud Cover**: 0%\n- **Feels Like**: 25.7°C (78.3°F)\n- **Wind Chill**: 21.1°C (70.0°F)\n- **Heat Index**: 24.5°C (76.0°F)\n- **Dew Point**: 13.6°C (56.5°F)\n- **Visibility**: 10.0 km (6.0 miles)\n- **UV Index**: 0.0\n- **Wind Gusts**: 21.8 mph (35.0 kph)\n\nThe weather is clear with no cloud cover, and the temperature feels warm and pleasant."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"which city is hotter?\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "nTRExbnW-9L2",
        "outputId": "008d2d2d-b31c-4a54-87c8-e617de55f21b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Currently, Dubai is hotter than Bangalore. The temperature in Dubai is 24.3°C (75.7°F), while in Bangalore, it is 21.1°C (70.0°F)."
          },
          "metadata": {}
        }
      ]
    }
  ]
}