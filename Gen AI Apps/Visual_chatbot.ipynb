{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Visual Chatbot App with ChatGPT, LangChain and Streamlit"
      ],
      "metadata": {
        "id": "fVq58fNksLAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.1.12 --quiet\n",
        "!pip install langchain-openai==0.0.8 --quiet\n",
        "!pip install langchain-community==0.0.29 --quiet\n",
        "!pip install streamlit==1.32.2 --quiet\n",
        "!pip install pyngrok==7.1.5 --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qT5QQxnsd_-",
        "outputId": "461fafba-2fa2-42f8-faa7-b296502ed14c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/809.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m460.8/809.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPEN_API_KEY')\n",
        "os.environ['NGROK_AUTH_TOKEN'] = userdata.get('NGROK_AUTH_TOKEN')\n"
      ],
      "metadata": {
        "id": "8SY_08rLsqZF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## App Code"
      ],
      "metadata": {
        "id": "v60cxzucs3Ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import openai\n",
        "import io\n",
        "import base64\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# OpenAI API Key (Replace with your API key or set it as an environment variable)\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']\n",
        "\n",
        "# Streamlit App Configuration\n",
        "st.set_page_config(page_title=\"Visual Chatbot\", page_icon=\"ðŸ¤–\")\n",
        "st.title(\"ðŸ¤– Visual Chatbot\")\n",
        "\n",
        "# File uploader for an optional image\n",
        "uploaded_file = st.file_uploader(\"Upload an image (optional)\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "img_base64 = None\n",
        "if uploaded_file:\n",
        "    # Display the uploaded image\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "    # Convert image to Base64 string\n",
        "    img_bytes = io.BytesIO()\n",
        "    image.save(img_bytes, format=\"PNG\")\n",
        "    img_base64 = base64.b64encode(img_bytes.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "# User input for a question\n",
        "user_question = st.text_input(\"Ask your question:\")\n",
        "\n",
        "if user_question:\n",
        "    # Build the messages list\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
        "    ]\n",
        "    if img_base64:\n",
        "        # If an image is uploaded, include both text and image in the user message\n",
        "        messages.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": user_question},\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}}\n",
        "            ]\n",
        "        })\n",
        "    else:\n",
        "        # No image: use a simple text message\n",
        "        messages.append({\"role\": \"user\", \"content\": user_question})\n",
        "\n",
        "    # Call GPT-4o using the new client interface\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4o\",  # Replace with your desired multi-modal model if needed\n",
        "        messages=messages,\n",
        "        max_tokens=150\n",
        "    )\n",
        "\n",
        "    # Extract and display the response using dot notation\n",
        "    ai_response = response.choices[0].message.content\n",
        "    st.subheader(\"ðŸ¤– AI Response:\")\n",
        "    st.write(ai_response)\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.caption(\"ðŸ” Powered by OpenAI GPT-4o & Streamlit\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkSPGE-Gs763",
        "outputId": "2389e9c9-d003-4d50-be49-159139f87c32"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port=8989 &>./logs.txt &"
      ],
      "metadata": {
        "id": "xpOak3CMt9_E"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import yaml\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken\n",
        "# Get your authtoken from `ngrok_credentials.yml` file\n",
        "# with open('ngrok_credentials.yml', 'r') as file:\n",
        "#     NGROK_AUTH_TOKEN = yaml.safe_load(file)\n",
        "ngrok.set_auth_token(os.environ['NGROK_AUTH_TOKEN'] )\n",
        "\n",
        "# Open an HTTPs tunnel on port XXXX which you get from your `logs.txt` file\n",
        "ngrok_tunnel = ngrok.connect(8989)\n",
        "print(\"Streamlit App:\", ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzoAxZQGuAJ8",
        "outputId": "62d6b773-c931-4a56-f340-447814ccbffe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit App: https://8e17-35-243-149-155.ngrok-free.app\n"
          ]
        }
      ]
    }
  ]
}